# Literature Survey on Hallucination Evaluation in Large Language Models: State-of-the-Art (SOTA)

**Institution:** Khoury College of Computer Sciences, Northeastern University  

## Overview

This repository contains the research paper and supporting resources for the literature survey titled **"Hallucination Evaluation in Large Language Models (LLMs): State-of-the-Art (SOTA)"**. The survey investigates the challenges and advancements in evaluating and mitigating hallucinations in LLMs and Multimodal LLMs (LMMs).

Hallucinations—plausible yet incorrect outputs generated by LLMs—pose significant challenges in high-stakes applications like healthcare, education, and legal advice. This work reviews ten key studies from 2020 to 2024, categorizing benchmarks, identifying gaps, and proposing future directions for the field.

---

## Contents

- **Introduction**: Background and objectives of the study.  
- **Methodology**: Search strategy, keywords, selection criteria, and data distribution.  
- **Literature Review**: Thematic and comparative analysis of existing benchmarks and methods.  
- **Critical Analysis**: Evaluation of research quality, insights, gaps, and implications.  
- **Conclusion**: Summary of findings and recommendations for future research.  

---

## Key Features of the Paper

### Objectives:
1. **Identify Contributing Factors**: Analyze key causes of hallucinations, such as training data quality and model architecture.
2. **Assess Impact**: Evaluate how hallucinations affect model reliability in real-world applications.
3. **Evaluate Mitigation Strategies**: Review techniques like Chain-of-Thought prompting, external knowledge integration, and reinforcement learning.
4. **Highlight Research Gaps**: Address interpretability, energy efficiency, and cultural diversity.

### Findings:
- Benchmarks like DAHL, HalluQA, and Reefknot address domain-specific hallucinations.
- Techniques like real-time augmentation and confidence-based scoring enhance factual consistency.
- Persistent gaps include cultural representation, interpretability, and real-time evaluation frameworks.

### Recommendations:
- Expand benchmarks to cover diverse languages and cultural contexts.
- Innovate in energy-efficient training and inference techniques.
- Develop hybrid models that integrate structured and unstructured data.


## Installation and Usage

### Prerequisites
- Python 3.8 or higher
- Jupyter Notebook
- Pandas, Matplotlib, and other Python libraries

---

## Contribution Guidelines

We welcome contributions to extend this work, especially in the following areas:
- Adding new benchmarks and datasets to evaluate hallucinations.
- Improving existing scripts for analysis and visualization.
- Translating benchmarks into more diverse languages and cultural contexts.


---

## License

This project is licensed under the [MIT License](LICENSE). You are free to use, modify, and distribute this work with proper attribution.

---

## Contact

For any inquiries or collaboration opportunities, please reach out to the authors:  
- **Yash Khare**: [khare.y@northeastern.edu](mailto:khare.y@northeastern.edu)  
- **Mohan Bhosale**: [bhosale.m@northeastern.edu](mailto:bhosale.m@northeastern.edu)  

---
